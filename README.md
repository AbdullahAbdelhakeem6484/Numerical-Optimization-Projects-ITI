# Numerical-Optimization-Projects-ITI
BATCH GD -  MINI BATCH GD - STOCHASTIC GD -MOMENTUM Based - NESTROV  - ADAGRAD - RMSP PROB- ADAM  .  During logistic regression, in order to compute the optimal parameters in the model, we have to use an iterative numerical optimization approach (Newton method or Gradient descent method, instead of a simple analytical approach). Numerical optimization is a crucial mathematical concept in machine learning and function fitting, and it is deeply integrated in model training, regularization, support vector machine, neural network, and so on. In the next few posts, I will summarize key concepts and approaches in numerical optimization, and its application in machine learning.


# Projects in Master Branch
